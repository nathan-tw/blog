[{"content":"  distributed network, src: https://unsplash.com/photos/OKOOGO578eo\n  前言 繼上一篇[技術雜談] 你不能不知道的軟體架構\u0026ndash;MapReduce (一)提到的MapReduce概念，這篇講解的是如何完成MIT 6.824的Lab1，自幹一個MapReduce核心。雖然網路上許多人說這個 Lab不難，但其實我花了不少的時間(汗)，而且因為是由golang完成的，對goroutine與channel又必須有一些了解，所以我認為沒學過go的人要完成是蠻有挑戰的，也因為這樣，以下的軟體結構我盡量以圖來說明，程式碼的部分瀏覽即可。\n題目要求 首先我們再回顧一下論文中的圖：\n  mapReduce in paper\n  我將Lab1中的幾個重點列出，由於並非全部要求，若想完成Lab還是需要看原網址的描述。\n 設計一個分散式的MapReduce系統，其中包含兩個程式：Coordinator和Worker。 系統架構中只有一個Coordinator，一或多個Worker平行運行。 兩者之間的溝通透過RPC (Remote Procedure Call)。 Map階段將中介的key (前篇提到的k2)利用hash分成nReduce組。 第X組的Reduce任務輸出命名為mr-out-X。 中介檔案 (Map的產物)命名為mr-X-Y。 主程序會隔三差五的呼叫Done確認任務是否全數完成。  系統架構設計 根據以上幾點要求，我的想法是：\n 用一個會block的queue (channel in golang)作為任務佇列。 將任務分為兩階段：Map和Reduce，當所有任務的Map階段完成後，在最新一次Done被呼叫時更新狀態為Reduce階段。 Worker不停向Master (Coordinator)要求任務，並更新自身狀態  設計上如下圖：\n  my mapReduce design\n  基本上如果只是要理解設計的話到這就結束了，接下來會談在程式碼上如何實作。我們先從Coordinator和Worker的主程式開始看起：\n// main/mrcoordinator.go func main() { if len(os.Args) \u0026lt; 2 { fmt.Fprintf(os.Stderr, \u0026#34;Usage: mrcoordinator inputfiles...\\n\u0026#34;) os.Exit(1) } // 第一個參數是*.txt，代表切分後的文件 \t// 第二個參數則是worker數量(nReduce) \tm := mr.MakeCoordinator(os.Args[1:], 10) for m.Done() == false { time.Sleep(time.Second) } time.Sleep(time.Second) } // main/mrworker.go  func main() { if len(os.Args) != 2 { fmt.Fprintf(os.Stderr, \u0026#34;Usage: mrworker xxx.so\\n\u0026#34;) os.Exit(1) } mapf, reducef := loadPlugin(os.Args[1]) mr.Worker(mapf, reducef) } 可以從上面的程式看到Coordinator啟動後會每過一秒確認一次任務完成了嗎，而這個Lab還有一個要求是測試的程式mian/test-mr.sh要在10s內完成。而下方的Worker很簡單，就是單純的把mapf和reducef傳入即可。接者我們看看Coordinator本身的設計：\ntype Coordinator struct { TaskChan chan Task // 任務等待的quque \tFiles []string // 要處理的文件 \tMapNum int // nMap, 要處理的map任務數量，其實就是files數量 \tReduceNum int // nReduce, reduce任務數量 \tTaskPhase int // 0: mapPhase, 1: reducePhase \tTaskState []TaskState // 任務狀態 \tMutex sync.Mutex // 互斥鎖, 以防coordinator的狀態被不同worker同時讀寫 \tIsDone bool //任務是否全數完成 } 簡單來說，由於Coordinator要處理讀取任務(input)和Worker請求(output)兩者，就必須兼具分派任務且維持本身資訊穩定的特性，也因此需要Mutex來處理。更細部的處理，例如Task和TaskState的設計可以到我的專案看，這裡就不贅述，接著看Worker的設計：\nfunc Worker(mapf func(string, string) []KeyValue, reducef func(string, []string) string) { for { reply := requestTask() // 只有在任務全數完成時，回傳會是true \tif reply.TaskDone { break } err := do(mapf, reducef, reply.Task) if err != nil { reportTask(reply.Task.TaskIndex, false) // 回傳任務, 如果任務出錯了, arg2給予false \tcontinue } reportTask(reply.Task.TaskIndex, true) } } 從主程序收到mapf及reducef後，worker就知道自己確切要做什麼了，因此流程很簡單：\n 請求任務。 執行任務 (do()中會處理任務型態為map或reduce)。 根據成功或失敗回報任務。 重複1~3直到任務都被完成。  如此一來每個worker都充分利用到，且可以處理執行錯誤的任務。\n結論 這裡會發現，許多concurrency的架構都採用類似 fan-in/fan-out的模型，意思就是由一個master處理分派工作和蒐集，並做到block等待的工作，第一次讀到這個模型是在Effective Python這本書中提到，其中包含了許多關於python設計中GIL (全域鎖) 的用途及multi-thread使用方式，如對分散系統有興趣非常推薦一試。6.824的第一個lab到此結束，下一個lab是關於分散式系統中的共識機制演算法Raft，對於Cloud Native越趨熱門的時代，了解這些架構及演算法對建構雲生態相當有幫助。\n心得 與其說是講解，不如說是在疫情期間為自己紀錄學習歷程，最近對分散式系統越發著迷，標題寫著你不能不知道...，但其實潛台詞是在責怪我自己，明明想成為SRE，知道blockchain、用過nosql、學過data science，卻不知道他們每一個都和分散式系統密不可分，尤其blockchain本身就是一個分散式系統 (在6.824後段課程會講解)，想想還是應把基礎慢慢不足，現階段得趕快知道我必須讀什麼，當兵才不會太無聊。之後想寫一些關於github action如何部署hugo的網頁 (也就是此部落格的方式)。再次感謝看到這裡的你，祝你平安。\n","permalink":"http://nathan-tw.github.io/posts/mapreduce2/","summary":"distributed network, src: https://unsplash.com/photos/OKOOGO578eo\n  前言 繼上一篇[技術雜談] 你不能不知道的軟體架構\u0026ndash;MapReduce (一)提到的MapReduce概念，這篇講解的是如何完成MIT 6.824的Lab1，自幹一個MapReduce核心。雖然網路上許多人說這個 Lab不難，但其實我花了不少的時間(汗)，而且因為是由golang完成的，對goroutine與channel又必須有一些了解，所以我認為沒學過go的人要完成是蠻有挑戰的，也因為這樣，以下的軟體結構我盡量以圖來說明，程式碼的部分瀏覽即可。\n題目要求 首先我們再回顧一下論文中的圖：\n  mapReduce in paper\n  我將Lab1中的幾個重點列出，由於並非全部要求，若想完成Lab還是需要看原網址的描述。\n 設計一個分散式的MapReduce系統，其中包含兩個程式：Coordinator和Worker。 系統架構中只有一個Coordinator，一或多個Worker平行運行。 兩者之間的溝通透過RPC (Remote Procedure Call)。 Map階段將中介的key (前篇提到的k2)利用hash分成nReduce組。 第X組的Reduce任務輸出命名為mr-out-X。 中介檔案 (Map的產物)命名為mr-X-Y。 主程序會隔三差五的呼叫Done確認任務是否全數完成。  系統架構設計 根據以上幾點要求，我的想法是：\n 用一個會block的queue (channel in golang)作為任務佇列。 將任務分為兩階段：Map和Reduce，當所有任務的Map階段完成後，在最新一次Done被呼叫時更新狀態為Reduce階段。 Worker不停向Master (Coordinator)要求任務，並更新自身狀態  設計上如下圖：\n  my mapReduce design\n  基本上如果只是要理解設計的話到這就結束了，接下來會談在程式碼上如何實作。我們先從Coordinator和Worker的主程式開始看起：\n// main/mrcoordinator.go func main() { if len(os.Args) \u0026lt; 2 { fmt.Fprintf(os.Stderr, \u0026#34;Usage: mrcoordinator inputfiles.","title":"[技術雜談] 你不能不知道的軟體架構--MapReduce (二)"},{"content":"  spark and hadoop\n  前言 你肯定聽過大數據，甚至學會許多處理資料的方式，但在資訊爆炸的時代，企業要處理如此大量的資料通常不是依靠我們手上的小小筆電，那假如我們有了很多台機器然後呢？有什麼辦法是集結眾多機器的力量加速任務處理的呢？最近疫情嚴重在家讀MIT 6.824，對Google的AI大神Jeff Dean提出的MapReduce又認識了許多，之後許多知名的分散運算叢集都是基於這個概念，例如大家耳熟能詳的Hadoop和Spark，本篇文章將帶你深入淺出何謂MapReduce，下一篇則是以Go語言自幹一個MapReduce核心 ，有興趣可以先去我的github repo看。\n什麼是MapReduce 我們先想像有一個任務是要算出一篇很長的文章中字詞出現頻率，如果在同一台電腦我們會怎麼做呢？我們也許會遍歷整篇文章，並將字詞做紀錄，但若資料太大時這樣的方式並不可行，為了加速我們將檔案切分，並且產為經由Map function 產生 key-value pair如下：\nhello world -\u0026gt; {hello:1, world:1}\n接著將這些key-value pair 存成中介檔案後排序，Reduce function則根據key將所有value加總，如果以上流程在一台電腦上完成，會像下圖，前兩列中的A、B、C其實分別是Ａ:1、 B:1、C:1：\n  mapreduce in sequence, src: https://zhuanlan.zhihu.com/p/260752052\n  上面提到的任務如果在一個分散式的世界呢？Google提出的論文中有張重要的圖是這樣描述的：\n  mapreduce in distributed systems\n  MapReduce是一種軟體架構，由許多台機器組成，其中一台擔任Master，負責分派任務和處理來自Worker的RPC請求，其他則擔任Worker，負責處理使用者定義的Map和Reduce函式 也就是說只有可切分的大型任務才能應用MapReduce。而上面提到的例子如果以分散式系統實現，就會如下圖：\n  mapreduce in distributed systems, src: https://zhuanlan.zhihu.com/p/260752052\n  整個概念有點類似前陣子完成的Worker Pool，但是將thread改成分散於各個系統的Process。機器越多，系統擴展越困難，而MapReduce優雅的解決了這個問題，為了套用於許多不同的任務型態，mapreduce核心必須定義一致性的接口，這裏我們可以看到論文2.2提到的：\nmap (k1, v1) → list(k2, v2) reduce (k2, list(v2)) → list(v2) 在任務經過切分後，每個任務會交由一個mapper處理，而分配的機制則是誰有空誰就去處理(queue)。在word count的例子中，(k1, v1)代表切分後檔案名稱及內容，就是{filename, content}，而(k2, v2)則代表詞與頻率，也就是{hello: 1}。至於k2還有另一個用處，就是決定他要由哪個reducer處理，在產出中介檔案時就會依照mr-x-y命名，其中x代表map函數的index，y代表k2經過hash的值，這個值也同時是reducer的index。好的我知道許多人到這裡可能完全混亂，以下我用一張圖說明：\n  map function works in detail\n  可以清楚的看到切分後的小任務分別被機器執行，其實他們是在一個queue中等待分發，但這裡為了顯示不同檔案對應的流程才這樣畫，另一方面是想表示一個重要的概念，只有能夠切分的任務才能使用mapReduce。\n結論 以下整理幾個重點：\n 在分散式的世界中，效率是一致性的敵人(這裡的一致性指的是各個機器間的狀態)。 master負責分配任務，而任務分成map及reduce兩類。 mapReduce核心負責歸類和排序，使用者則定義map和reduce確切要做的事。 只有能夠切分的任務才能使用mapReduce。  心得 疫情肆虐，在家的各位好嗎？也許很多人的生涯規劃被打亂，期待許久的聚餐也迫於無奈取消，旅遊或生活都淪為遺憾。但在家依然有許多事可以做的，例如寫一篇廢廢的部落格聊聊近日所學，下一篇我會談談最近在看的課程MIT6.824中lab1的實作，著墨較多於系統設計，如果看不懂go也沒關係。 感謝你看到這裏，願你平安。\nReference  MapReduce Paper: https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf Hadoop: https://en.wikipedia.org/wiki/Apache_Hadoop Spark: https://en.wikipedia.org/wiki/Apache_Spark 知乎講解: https://zhuanlan.zhihu.com/p/260752052 我的Lab1: https://github.com/nathan-tw/6.824  ","permalink":"http://nathan-tw.github.io/posts/mapreduce/","summary":"spark and hadoop\n  前言 你肯定聽過大數據，甚至學會許多處理資料的方式，但在資訊爆炸的時代，企業要處理如此大量的資料通常不是依靠我們手上的小小筆電，那假如我們有了很多台機器然後呢？有什麼辦法是集結眾多機器的力量加速任務處理的呢？最近疫情嚴重在家讀MIT 6.824，對Google的AI大神Jeff Dean提出的MapReduce又認識了許多，之後許多知名的分散運算叢集都是基於這個概念，例如大家耳熟能詳的Hadoop和Spark，本篇文章將帶你深入淺出何謂MapReduce，下一篇則是以Go語言自幹一個MapReduce核心 ，有興趣可以先去我的github repo看。\n什麼是MapReduce 我們先想像有一個任務是要算出一篇很長的文章中字詞出現頻率，如果在同一台電腦我們會怎麼做呢？我們也許會遍歷整篇文章，並將字詞做紀錄，但若資料太大時這樣的方式並不可行，為了加速我們將檔案切分，並且產為經由Map function 產生 key-value pair如下：\nhello world -\u0026gt; {hello:1, world:1}\n接著將這些key-value pair 存成中介檔案後排序，Reduce function則根據key將所有value加總，如果以上流程在一台電腦上完成，會像下圖，前兩列中的A、B、C其實分別是Ａ:1、 B:1、C:1：\n  mapreduce in sequence, src: https://zhuanlan.zhihu.com/p/260752052\n  上面提到的任務如果在一個分散式的世界呢？Google提出的論文中有張重要的圖是這樣描述的：\n  mapreduce in distributed systems\n  MapReduce是一種軟體架構，由許多台機器組成，其中一台擔任Master，負責分派任務和處理來自Worker的RPC請求，其他則擔任Worker，負責處理使用者定義的Map和Reduce函式 也就是說只有可切分的大型任務才能應用MapReduce。而上面提到的例子如果以分散式系統實現，就會如下圖：\n  mapreduce in distributed systems, src: https://zhuanlan.zhihu.com/p/260752052\n  整個概念有點類似前陣子完成的Worker Pool，但是將thread改成分散於各個系統的Process。機器越多，系統擴展越困難，而MapReduce優雅的解決了這個問題，為了套用於許多不同的任務型態，mapreduce核心必須定義一致性的接口，這裏我們可以看到論文2.2提到的：\nmap (k1, v1) → list(k2, v2) reduce (k2, list(v2)) → list(v2) 在任務經過切分後，每個任務會交由一個mapper處理，而分配的機制則是誰有空誰就去處理(queue)。在word count的例子中，(k1, v1)代表切分後檔案名稱及內容，就是{filename, content}，而(k2, v2)則代表詞與頻率，也就是{hello: 1}。至於k2還有另一個用處，就是決定他要由哪個reducer處理，在產出中介檔案時就會依照mr-x-y命名，其中x代表map函數的index，y代表k2經過hash的值，這個值也同時是reducer的index。好的我知道許多人到這裡可能完全混亂，以下我用一張圖說明：","title":"[技術雜談] 你不能不知道的軟體架構--MapReduce (一)"},{"content":"  my github contribution\n  背景 投遞時間落在2021/3-5月，大四即將畢業，實在對讀書沒什麼熱忱，雖然讀碩對職涯來說體質比較好，試著花了大約一個半月讀研究所(看github 的 contribution就知道有一個多月的空白qq)，但最後只有備取就認命開始找工作吧。想過將兵役提前，但今年因為疫情許多本來要出國的人或在國外的學生回台，造成等待兵役的人數增加，提前未必能在畢業後馬上進入軍營，於是有了先找工作慢慢等兵單的念頭，因此主要找的是可以給preoffer或以轉正為目標的實習為主。\nDcard (backend intern)   dcard logo\n  從大二就注意到Dcard的實習了，第一印象是年輕有活力的公司讓我很嚮往，但那時我的web知識匱乏連題目都看不懂(題目google就有，每年都一樣)，只好花時間多充實自己。大三時看到一位厲害的學長分享Dcard實習，覺得裡面的人對技術都相當有熱忱，也在gopher conf聽了Dcard backend精彩的演講，於是這次完成了作業決定嘗試看看。\n作業要求 Dcard 每天午夜都有大量使用者湧入抽卡，請設計一個 middleware：\n 限制每小時來自同一個 IP 的請求數量不得超過 1000 在 response headers 中加入剩餘的請求數量 (X-RateLimit-Remaining) 以及 rate limit 歸零的時間 (X-RateLimit-Reset) 如果超過限制的話就回傳 429 (Too Many Requests) 可以使用各種資料庫達成  實做方式 限定只能用golang或nodejs，資料庫並沒有限制。我是以golang寫，資料庫的部份以單線程為主的redis，使得單個transaction不用考慮race condition，加上存取快速高併發的特性，以及方便的ttl對這次的作業十分友善，因此選擇redis作為這次作業的資料庫。至於來自不同client的get和set可能造成race condition，我在github repo中有詳細說明我如何實做lock。\n一面 可以提早到hr會帶你參觀辦公室，由兩位backend面試後換hr面，先自我介紹約5-10分鐘，backend會針對以前的專案經驗追根究底的問，一定要對自己做過的專案非常熟悉，不然會和我一樣被問倒XD，加上以前在底層的計算機基礎知識不夠扎實，例如被問到為何mips要分成五個stage的pipeline來設計，當場腦袋空白只好說不知道，結果離開後馬上想到zzz。所以基礎也非常重要，面完就知道不會上了，期待蠻久的面試以失望落幕，果然自己還有許多基礎需要補足。和hr的面試就是一般的behavior問題，這個網路上有許多厲害的技巧分享，我就不多花篇幅了。\n結果 感謝信\nIBM (Associate developer) 官網投遞校園招募後一星期收到線上趣味測驗，趣味測驗結束就收到感謝信了。\n結果 感謝信\nAmazon Ring (SWE)   amazon ring\n  官網投遞校園招募後一星期收到線上測驗。\nOnsite Assignment 總共有三題，分別是easy, hard, medium。只能用四種語言: C, C++, Java, Python，職位的語言偏好也是前面的順序，第一次看到大科技公司對語言有偏好的，由於C-like的語言都不太熟，Java寫起來也不心安，雖然是最低順位的語言但也只能用Python了。\n答題過程 總共有90分鐘，第一題花了15-20分鐘，以easy來說蠻久的，讓我想花更多時間學好英文，不然閱讀速度太慢蠻虧的。第二題是比較複雜的背包問題，因為太久沒寫DP，花了很多時間還是沒寫出來，剩下20分鐘時放棄轉看第三題。結果第三題也是DP，比較基本的二維DP，看完還蠻有信心做出來，但後來和時間賽跑太緊張，index一直算錯還是沒有完成。雖然還沒收到信，但應該是沒什麼機會。\n更新後續 後來收到信說，這個職位比較偏向硬體的部份，OA僅能用C/C++完成，由於我是用python，於是HR問我要不要再用C like語言寫一次，但我實在對這樣的職務內容沒興趣，且對這兩個語言相當不熟，因此拒絕了機會。\n結果 reject\nGarmin (SRE intern)   garmin logo\n  在臉書社團看到的職位，實習期間為7-8月，算了一下和實習結束兵單應該差不多到，如果沒到可以去面更多不同的公司，看了許多關於garmin的薪資調查，以軟體來說應該算還不錯的，所以這個實習的目的除了接觸更多SRE實務經驗，有很大一部份是為了轉正而實習。1111投遞履歷後收到面試通知。\n面試 總部在汐止，但實習地點在林口，剛好離家不遠，不過當天騎到汐止的路上天色昏暗加上毛毛細雨，一路上看起來都相當荒涼，心中暗自慶幸自己不是在這上班。面試會先請你自我介紹，不會有白板題(其實還蠻期待的)。由於目前的實習也是SRE相關職務，所以講完自己的學經歷後就分享了自己對這職位的想法。我認為SRE對任何東西都需要了解一些，因為你不知道與自己對接的是怎樣的開發團隊，其實講到一點很有趣的是我大學跟風學了ML/AI的皮毛，但越是深入越是感覺無力以及渺小，之後便果斷放棄資料科學家一途。面試時我向面試官提到我有一個優勢是對ML有基礎的了解，剛好他們也有Data的團隊在嘗試DevOps，總覺得是命運使然，面試結束我蠻有信心會上的。\n 我相信努力不會騙人，也相信沒有路是白走的\n 結果 Offer Get\n小節 最後去了Garmin，但因為只是實習而已，所以實習尾聲如果有更多心得應該會更新，雖然是以轉正為目標，但還是會憧憬FANG的生活，無論是作夢或是野心，都會不斷訓練自己朝這個方向努力，尤其會更加強自己的英文\u0026gt;\u0026lt;如果文章有幫助到你，歡迎email和我聊聊，或是任何社交軟體私訊我我都會看到～\n","permalink":"http://nathan-tw.github.io/posts/intern/","summary":"my github contribution\n  背景 投遞時間落在2021/3-5月，大四即將畢業，實在對讀書沒什麼熱忱，雖然讀碩對職涯來說體質比較好，試著花了大約一個半月讀研究所(看github 的 contribution就知道有一個多月的空白qq)，但最後只有備取就認命開始找工作吧。想過將兵役提前，但今年因為疫情許多本來要出國的人或在國外的學生回台，造成等待兵役的人數增加，提前未必能在畢業後馬上進入軍營，於是有了先找工作慢慢等兵單的念頭，因此主要找的是可以給preoffer或以轉正為目標的實習為主。\nDcard (backend intern)   dcard logo\n  從大二就注意到Dcard的實習了，第一印象是年輕有活力的公司讓我很嚮往，但那時我的web知識匱乏連題目都看不懂(題目google就有，每年都一樣)，只好花時間多充實自己。大三時看到一位厲害的學長分享Dcard實習，覺得裡面的人對技術都相當有熱忱，也在gopher conf聽了Dcard backend精彩的演講，於是這次完成了作業決定嘗試看看。\n作業要求 Dcard 每天午夜都有大量使用者湧入抽卡，請設計一個 middleware：\n 限制每小時來自同一個 IP 的請求數量不得超過 1000 在 response headers 中加入剩餘的請求數量 (X-RateLimit-Remaining) 以及 rate limit 歸零的時間 (X-RateLimit-Reset) 如果超過限制的話就回傳 429 (Too Many Requests) 可以使用各種資料庫達成  實做方式 限定只能用golang或nodejs，資料庫並沒有限制。我是以golang寫，資料庫的部份以單線程為主的redis，使得單個transaction不用考慮race condition，加上存取快速高併發的特性，以及方便的ttl對這次的作業十分友善，因此選擇redis作為這次作業的資料庫。至於來自不同client的get和set可能造成race condition，我在github repo中有詳細說明我如何實做lock。\n一面 可以提早到hr會帶你參觀辦公室，由兩位backend面試後換hr面，先自我介紹約5-10分鐘，backend會針對以前的專案經驗追根究底的問，一定要對自己做過的專案非常熟悉，不然會和我一樣被問倒XD，加上以前在底層的計算機基礎知識不夠扎實，例如被問到為何mips要分成五個stage的pipeline來設計，當場腦袋空白只好說不知道，結果離開後馬上想到zzz。所以基礎也非常重要，面完就知道不會上了，期待蠻久的面試以失望落幕，果然自己還有許多基礎需要補足。和hr的面試就是一般的behavior問題，這個網路上有許多厲害的技巧分享，我就不多花篇幅了。\n結果 感謝信\nIBM (Associate developer) 官網投遞校園招募後一星期收到線上趣味測驗，趣味測驗結束就收到感謝信了。\n結果 感謝信\nAmazon Ring (SWE)   amazon ring","title":"[心得] 2021面試心得 Dcard/Garmin/Amazon/IBM"},{"content":"not done yet\n","permalink":"http://nathan-tw.github.io/about/","summary":"not done yet","title":"About"},{"content":"  unsplash: https://unsplash.com/photos/cABs_SSYua0\n  Star67 其實部落格的命名和星星完全沒有關係，大學時在新光路67號住了最久，也最喜歡在那生活的日子，所以部落格本想以此為名，不過如果取為New67或是Light67聽起來蠻蠢的，所以乾脆想成Star67aka星光路67號，而且在這的日子常常熬夜，五成是和朋友打傳說通霄，另外五成則是寫程式和書法到半夜停不下來所致，這些事的樂趣是日光還在時體會不到的，畢竟深夜才是適合苦惱的時候，而苦惱正是這些事精華之處。即使每天早上都不省人事，卻很享受這種報復性的作息，享受這種女友睡了，鄰居關燈了，剩下星光亮著的時光。\n重蹈覆轍  愛是讓你不重蹈覆轍，讓你生而為人 \u0026ndash; 羅于婷 \u0026lt;喜歡的話可以試穿\u0026gt;\n 其實大二大三時試著寫過medium，但一方面覺得自己的文章沒有質感，另一方面自己在技術上沒什麼可以分享或紀錄的，懷疑過現在的自己是否重蹈覆轍。直到最近聽到一首神曲走建國路回家但後座少ㄌ泥，我認為不管有沒有人看，寫的多爛，甚至什麼都沒學到，就去寫吧，寫的過程也許就是意義，一如那些星光陪伴的日子，寫下許多許多的字從來就不是為了讓誰滿意，而是我就想任性放肆的寫而已。\n  ","permalink":"http://nathan-tw.github.io/posts/star67/","summary":"  unsplash: https://unsplash.com/photos/cABs_SSYua0\n  Star67 其實部落格的命名和星星完全沒有關係，大學時在新光路67號住了最久，也最喜歡在那生活的日子，所以部落格本想以此為名，不過如果取為New67或是Light67聽起來蠻蠢的，所以乾脆想成Star67aka星光路67號，而且在這的日子常常熬夜，五成是和朋友打傳說通霄，另外五成則是寫程式和書法到半夜停不下來所致，這些事的樂趣是日光還在時體會不到的，畢竟深夜才是適合苦惱的時候，而苦惱正是這些事精華之處。即使每天早上都不省人事，卻很享受這種報復性的作息，享受這種女友睡了，鄰居關燈了，剩下星光亮著的時光。\n重蹈覆轍  愛是讓你不重蹈覆轍，讓你生而為人 \u0026ndash; 羅于婷 \u0026lt;喜歡的話可以試穿\u0026gt;\n 其實大二大三時試著寫過medium，但一方面覺得自己的文章沒有質感，另一方面自己在技術上沒什麼可以分享或紀錄的，懷疑過現在的自己是否重蹈覆轍。直到最近聽到一首神曲走建國路回家但後座少ㄌ泥，我認為不管有沒有人看，寫的多爛，甚至什麼都沒學到，就去寫吧，寫的過程也許就是意義，一如那些星光陪伴的日子，寫下許多許多的字從來就不是為了讓誰滿意，而是我就想任性放肆的寫而已。\n  ","title":"[生活碎念] 關於Star67"},{"content":"前陣子在準備Dcard實習的面試，看到別人的心得被問到如何以Golang實做一個Worker Pool，於是自己嘗試寫了一個。\n什麼是Worker Pool Worker Pool是一個以multithread組成的任務處理模型，producer產生許多任務，並交由workers並行處理這些任務，最後將任務結果蒐集起來，這樣的作法可以有效的運用電腦資源，並快速處理重複性高且獨立的作業。\nWorker Pool 設計 Type 定義 Worker Pool可以有一定數量的Workers(PoolSize)，並且可以指定一次處理的任務數量(tasksSize)，交由tasksChan送給worker，處理後再經由resultsChan存起來，待Results被呼叫時一一取出。而Task則是定義了id, error 和如何process的function。\ntype Task struct { Id int Err error f func() error } type WorkerPool struct { PoolSize int tasksSize int tasksChan chan Task resultsChan chan Task Results func() []Task } 功能實做 每一個任務處理完都會回傳error，如順利完成則回傳nil，至於任務如何執行則是依據新增任務時給定。\nfunc (task *Task) Do() error { return task.f() Worker Pool是利用buffered channel做任務的通道，所以可以經由Start將worker一一執行起來後，讓worker利用range的特性不斷監聽是否有任務可以做。\nfunc NewWorkerPool(tasks []Task, size int) *WorkerPool { tasksChan, resultsChan := make(chan Task, len(tasks)), make(chan Task, len(tasks)) for _, task := range tasks { tasksChan \u0026lt;- task } close(tasksChan) pool := \u0026amp;WorkerPool{ PoolSize: size, tasksSize: len(tasks), tasksChan: tasksChan, resultsChan: resultsChan, } pool.Results = pool.results return pool } func (pool *WorkerPool) Start() { for i := 0; i \u0026lt; pool.PoolSize; i++ { go pool.worker() } } func (pool *WorkerPool) worker() { for task := range pool.tasksChan { task.Err = task.Do() pool.resultsChan \u0026lt;- task } } func (wp *WorkerPool) results() []Task { tasks := make([]Task, wp.tasksSize) for i := 0; i \u0026lt; wp.tasksSize; i++ { tasks[i] = \u0026lt;-wp.resultsChan } return tasks } 小結 由於是第一次寫blog很多想法還沒結構化，寫文章也非常沒有系統性，如果有任何意見可以email (linnom987321@gmail.com)我。Worker Pool的作法其實有很多變化，我看過有人用Sync.Waitgroup做，也有人用mutex及unbuffered channel，我的實做及相關的連結在reference提供給大家。\nReference  https://github.com/nathan-tw/workerpool https://github.com/gammazero/workerpool https://github.com/xxjwxc/gowp  ","permalink":"http://nathan-tw.github.io/posts/worker-pool/","summary":"前陣子在準備Dcard實習的面試，看到別人的心得被問到如何以Golang實做一個Worker Pool，於是自己嘗試寫了一個。\n什麼是Worker Pool Worker Pool是一個以multithread組成的任務處理模型，producer產生許多任務，並交由workers並行處理這些任務，最後將任務結果蒐集起來，這樣的作法可以有效的運用電腦資源，並快速處理重複性高且獨立的作業。\nWorker Pool 設計 Type 定義 Worker Pool可以有一定數量的Workers(PoolSize)，並且可以指定一次處理的任務數量(tasksSize)，交由tasksChan送給worker，處理後再經由resultsChan存起來，待Results被呼叫時一一取出。而Task則是定義了id, error 和如何process的function。\ntype Task struct { Id int Err error f func() error } type WorkerPool struct { PoolSize int tasksSize int tasksChan chan Task resultsChan chan Task Results func() []Task } 功能實做 每一個任務處理完都會回傳error，如順利完成則回傳nil，至於任務如何執行則是依據新增任務時給定。\nfunc (task *Task) Do() error { return task.f() Worker Pool是利用buffered channel做任務的通道，所以可以經由Start將worker一一執行起來後，讓worker利用range的特性不斷監聽是否有任務可以做。\nfunc NewWorkerPool(tasks []Task, size int) *WorkerPool { tasksChan, resultsChan := make(chan Task, len(tasks)), make(chan Task, len(tasks)) for _, task := range tasks { tasksChan \u0026lt;- task } close(tasksChan) pool := \u0026amp;WorkerPool{ PoolSize: size, tasksSize: len(tasks), tasksChan: tasksChan, resultsChan: resultsChan, } pool.","title":"[技術雜談] Worker Pool併發處理模型"}]