<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>林宣佑 | Nathan Lin</title>
    <link>http://nathan-tw.github.io/</link>
    <description>Recent content on 林宣佑 | Nathan Lin</description>
    <image>
      <url>http://nathan-tw.github.io/papermod-cover.png</url>
      <link>http://nathan-tw.github.io/papermod-cover.png</link>
    </image>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Aug 2021 09:03:34 -0400</lastBuildDate><atom:link href="http://nathan-tw.github.io/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>[生活] 夏夜夢迴</title>
      <link>http://nathan-tw.github.io/posts/university/</link>
      <pubDate>Wed, 18 Aug 2021 09:03:34 -0400</pubDate>
      
      <guid>http://nathan-tw.github.io/posts/university/</guid>
      <description>更悲觀更要體貼悲觀，別輕易離席  更要對一切不為你所愛更動秩序  更悲觀更要早睡早起，細細感覺自己  戒掉一直說對不起 
 每次讀最喜歡的詩集&amp;lt;更悲觀更要&amp;gt;心都會舒坦不少，悲觀面對慌張卻累積了悲觀，畢業後、當兵前像立於吊橋正中，整整四年沒有收拾好的心情最容易在夏夜散落，趁著實習即將結束趕緊把一葉葉的回憶收好。
升大學環島 東部 趁著升大學前還能自稱青春高中生時環了一次島，二馬、肥肥、西打和我四種迥然的個性，像是四季。先從宜蘭向東，雖然好幾個颱風即將接連來到，但我們依舊不聽長輩勸阻在花蓮停下，反正住宿費用肯定是他們出(?)，在離開花蓮前西打的手機壞了，颱風也差不多登陸，這是巧合嗎？我不這認為。一路還算從容的帶走幾片風景，飛速來到高雄。
  升大學環島時在粉鳥林
  南部 第一個到的點是高雄，也是最經典的一個城市因為我們待了 4 還 5 天，不是高雄多好玩只是颱風我們哪也不能去，就四個人在城市商旅整天打傳說講幹話，完全不知道做了什麼反正超級快樂跟嗑藥沒兩樣。颱風走後去了鋼筆店，見了一堆筆友，還打了撞球算是圓滿。接著到台南四個男生肯定是兩台機車橫衝直撞起來，從市區騎到七股真的很鬼，沒想到同樣的戲碼台中再次上演。
  成功人到哪裡都要成功褲
  中部 台中一直是我很喜歡的城市，因為哪裡都會下雨只有台中不會，但如果要我再從市區騎車到高美真的會哭出來，雖然也不是我騎的但屁股痛到不行。在台中基本上由甲哥當導遊，不得不說他的品味真的很好，相處起來真的感覺是非常有氣質的人，帶我們去了很多私密的景點，這可能是後來我一直去台中的原因之一。
  黑到不行的我
  相較於同個暑假去日本我反而更喜歡這種旅行，雖然日本很美很多新鮮的體驗，但與人的相處是取代不了的。
大一住宿 大一時住在山上，室友各自作息不一，理組的兩個室友花了許多時間在讀書但我對未來毫無想法，與其說資管系本質如此，不如說高中選組時的我就是這樣，沒有特別愛好什麼也不曾擅長什麼，就是男校中很平凡的縮影。後來應數的室友轉學了，我和另外兩位室友感情還算不錯，尤其資科系的和我一樣宅而且有一樣的方向，到現在久久會約一次吃飯。可惜疫情爆發沒能找他們拍張畢業照好好道別。除去室友外，還有大一必去的宿舍餐廳安九 (老王樂隊也是政大校友，下面這首歌就是以此為名)，最常和系上同學在這討論報告或慶生聊天，也會遇到很多通識課的同學，印象最深是聽著幾個有才的朋友唱歌談吉他，音癡的我負責享受順便錄音，在整個大學煩惱和能力都還沒有萌芽的大一生活裡，我最想念的是和室友半夜趴在地上玩毛筆以及安九的各項回憶。
  三更半 ya 從大一到大三漸淡的感情，謎樣的情感和模糊的記憶，人從多到少然後各自有了自己的棲息地，也沒辦法歸類誰屬於這裡，大一時一起夜唱過，大二辦過活動也頻繁出遊。雖然有過很多特別的事像是我要在山上辦系運佔場地所以前一天找了一堆人去過夜，以及半夜上山找螢火蟲，和其中一些人確實相處了很長一段時間卻也沒能真的形成聚落，可以和每個人說上話，但一方面沒人願意和剛上大學一樣袒露自己而且發生了太多的事，另一方面路已分岔人們各自離席，是大學想起來最遺憾的一些事，明明花了最多時間卻沒有更多的話可以描述。
  記憶中某次快樂出遊
  和這位的緣份更是奇妙，上大學第一個認識的人而且還是前期系桌的，因為是新竹人常常被我拿來消遣，但其實對人很好，甚至還是顏值擔當(有看過他西裝就知道)，不過也因為走不同的路後來並沒有太多交集，只知道好像要去美國讀書了希望他順利。
  我再次聲明，新竹就是美食沙漠
  系桌 大一大二 大一加入了系桌，迎新人很多但最後同屆只剩我的系桌，剛進來時一個說自己學過一點的人坐我旁邊，結果一開始打直接把我打成智障後來才知道他超強還加入校隊，大一結束基本上就沒有人要來打球了，只有隊長願意和我練習。下一屆學弟妹進來開心了一下但馬上就剩下一個學妹，幸好校外比賽還是可以把幾個厲害的人抓來幫忙。大二時資結助教也加入了系桌，她那時還不到很強，也不知道後來受了什麼刺激決定練好桌球，在我大三那年開始去找教練，後來在系桌我就沒有一個打得贏的人了，因為學妹也是校隊的超強。
  永遠看戰神們秀
  大三大四 不過雖然一直輸我還是很喜歡打桌球，輸的感覺不好可是至少有人願意和我玩(?)，而且我不知道是不是受他們影響開始喜歡寫程式，至少那時他們聊程式我完全聽不懂 (現在聽不懂的人剩學妹一個了嘻嘻)，大概也是他們迫使我進步吧直至疫情還沒結束的最近我們還是會聊程式和打球。另外要提一下有位學姐也幫我很多，和我同一個專案指導老師而且一直拿卷的學霸，雖然出現在系桌的時間不是特別多但因為系桌能認識她還獲得幫助真是太好了。
  湊人數還贏了</description>
    </item>
    
    <item>
      <title>[技術] 淺談 file descriptor 及 I/O Redirection</title>
      <link>http://nathan-tw.github.io/posts/io-redirection/</link>
      <pubDate>Wed, 07 Jul 2021 01:55:05 -0400</pubDate>
      
      <guid>http://nathan-tw.github.io/posts/io-redirection/</guid>
      <description>前言 fprintf(1, &amp;#34;hello world\n&amp;#34;); 你可能好奇過 C 語言fprintf函數中，第一個參數1代表什麼，你也許聽過在 Unix 家族中Everything is a file，可是他究竟代表什麼意思呢？這篇我們想談談究竟什麼是file，以及作業系統如何達到i/o redirection。
什麼是 file  Everything is a file
 先從這句話開始講起，在類 Unix 的設計中，對所有 I/O 資源的近用都是透過資料流的方式，也就是透過 file system 定義的檔案描述檔(file descriptor)來傳輸，當開啟這些資源時就會回傳一個 file descriptor，代表的就是對這個 file 的控制，例如大家熟悉的 System call open:
int open(char *file, int flags) 其中*file代表 path, flags代表 read/write，用法例如：
fd = open(&amp;#34;/tmp/temp&amp;#34;, O_WRONLY|O_CREAT); 那為什麼是回傳一個 int 呢？其實那個 int 就是 file descriptor，因為每個 process 都有一個 fd (file descriptor) table，其中包含了fd flag以及open file entry，根據xv6 book對其的描述是：
 A file descriptor is a small integer representing a kernel-managed object that a process may read from or write to.</description>
    </item>
    
    <item>
      <title>[技術] 你不能不知道的軟體架構--MapReduce (二)</title>
      <link>http://nathan-tw.github.io/posts/mapreduce2/</link>
      <pubDate>Tue, 01 Jun 2021 16:52:44 +0800</pubDate>
      
      <guid>http://nathan-tw.github.io/posts/mapreduce2/</guid>
      <description>前言 繼上一篇[技術雜談] 你不能不知道的軟體架構&amp;ndash;MapReduce (一)提到的MapReduce概念，這篇講解的是如何完成MIT 6.824的Lab1，自幹一個MapReduce核心。雖然網路上許多人說這個 Lab不難，但其實我花了不少的時間(汗)，而且因為是由golang完成的，對goroutine與channel又必須有一些了解，所以我認為沒學過go的人要完成是蠻有挑戰的，也因為這樣，以下的軟體結構我盡量以圖來說明，程式碼的部分瀏覽即可。
題目要求 首先我們再回顧一下論文中的圖：
  mapReduce in paper
  我將Lab1中的幾個重點列出，由於並非全部要求，若想完成Lab還是需要看原網址的描述。
 設計一個分散式的MapReduce系統，其中包含兩個程式：Coordinator和Worker。 系統架構中只有一個Coordinator，一或多個Worker平行運行。 兩者之間的溝通透過RPC (Remote Procedure Call)。 Map階段將中介的key (前篇提到的k2)利用hash分成nReduce組。 第X組的Reduce任務輸出命名為mr-out-X。 中介檔案 (Map的產物)命名為mr-X-Y。 主程序會隔三差五的呼叫Done確認任務是否全數完成。  系統架構設計 根據以上幾點要求，我的想法是：
 用一個會block的queue (channel in golang)作為任務佇列。 將任務分為兩階段：Map和Reduce，當所有任務的Map階段完成後，在最新一次Done被呼叫時更新狀態為Reduce階段。 Worker不停向Master (Coordinator)要求任務，並更新自身狀態  設計上如下圖：
  my mapReduce design
  基本上如果只是要理解設計的話到這就結束了，接下來會談在程式碼上如何實作。我們先從Coordinator和Worker的主程式開始看起：
// main/mrcoordinator.go func main() { if len(os.Args) &amp;lt; 2 { fmt.Fprintf(os.Stderr, &amp;#34;Usage: mrcoordinator inputfiles...\n&amp;#34;) os.Exit(1) } // 第一個參數是*.txt，代表切分後的文件 	// 第二個參數則是worker數量(nReduce) 	m := mr.</description>
    </item>
    
    <item>
      <title>[技術] 你不能不知道的軟體架構--MapReduce (一)</title>
      <link>http://nathan-tw.github.io/posts/mapreduce/</link>
      <pubDate>Sun, 23 May 2021 23:37:48 +0800</pubDate>
      
      <guid>http://nathan-tw.github.io/posts/mapreduce/</guid>
      <description>前言 你肯定聽過大數據，甚至學會許多處理資料的方式，但在資訊爆炸的時代，企業要處理如此大量的資料通常不是依靠我們手上的小小筆電，那假如我們有了很多台機器然後呢？有什麼辦法是集結眾多機器的力量加速任務處理的呢？最近疫情嚴重在家讀MIT 6.824，對Google的AI大神Jeff Dean提出的MapReduce又認識了許多，之後許多知名的分散運算叢集都是基於這個概念，例如大家耳熟能詳的Hadoop和Spark，本篇文章將帶你深入淺出何謂MapReduce，下一篇則是以Go語言自幹一個MapReduce核心 ，有興趣可以先去我的github repo看。
什麼是MapReduce 我們先想像有一個任務是要算出一篇很長的文章中字詞出現頻率，如果在同一台電腦我們會怎麼做呢？我們也許會遍歷整篇文章，並將字詞做紀錄，但若資料太大時這樣的方式並不可行，為了加速我們將檔案切分，並且產為經由Map function 產生 key-value pair如下：
hello world -&amp;gt; {hello:1, world:1}
接著將這些key-value pair 存成中介檔案後排序，Reduce function則根據key將所有value加總，如果以上流程在一台電腦上完成，會像下圖，前兩列中的A、B、C其實分別是Ａ:1、 B:1、C:1：
  mapreduce in sequence, src: https://zhuanlan.zhihu.com/p/260752052
  上面提到的任務如果在一個分散式的世界呢？Google提出的論文中有張重要的圖是這樣描述的：
  mapreduce in distributed systems
  MapReduce是一種軟體架構，由許多台機器組成，其中一台擔任Master，負責分派任務和處理來自Worker的RPC請求，其他則擔任Worker，負責處理使用者定義的Map和Reduce函式 也就是說只有可切分的大型任務才能應用MapReduce。而上面提到的例子如果以分散式系統實現，就會如下圖：
  mapreduce in distributed systems, src: https://zhuanlan.zhihu.com/p/260752052
  整個概念有點類似前陣子完成的Worker Pool，但是將thread改成分散於各個系統的Process。機器越多，系統擴展越困難，而MapReduce優雅的解決了這個問題，為了套用於許多不同的任務型態，mapreduce核心必須定義一致性的接口，這裏我們可以看到論文2.2提到的：
map (k1, v1) → list(k2, v2) reduce (k2, list(v2)) → list(v2) 在任務經過切分後，每個任務會交由一個mapper處理，而分配的機制則是誰有空誰就去處理(queue)。在word count的例子中，(k1, v1)代表切分後檔案名稱及內容，就是{filename, content}，而(k2, v2)則代表詞與頻率，也就是{hello: 1}。至於k2還有另一個用處，就是決定他要由哪個reducer處理，在產出中介檔案時就會依照mr-x-y命名，其中x代表map函數的index，y代表k2經過hash的值，這個值也同時是reducer的index。好的我知道許多人到這裡可能完全混亂，以下我用一張圖說明：</description>
    </item>
    
    <item>
      <title>[心得] 2021面試心得 Dcard/Garmin/Amazon/IBM</title>
      <link>http://nathan-tw.github.io/posts/intern/</link>
      <pubDate>Thu, 06 May 2021 01:28:04 -0400</pubDate>
      
      <guid>http://nathan-tw.github.io/posts/intern/</guid>
      <description>背景 投遞時間落在2021/3-5月，大四即將畢業，實在對讀書沒什麼熱忱，雖然讀碩對職涯來說體質比較好，試著花了大約一個半月讀研究所(看github 的 contribution就知道有一個多月的空白qq)，但最後只有備取就認命開始找工作吧。想過將兵役提前，但今年因為疫情許多本來要出國的人或在國外的學生回台，造成等待兵役的人數增加，提前未必能在畢業後馬上進入軍營，於是有了先找工作慢慢等兵單的念頭，因此主要找的是可以給preoffer或以轉正為目標的實習為主。
Dcard (backend intern)   dcard logo
  從大二就注意到Dcard的實習了，第一印象是年輕有活力的公司讓我很嚮往，但那時我的web知識匱乏連題目都看不懂(題目google就有，每年都一樣)，只好花時間多充實自己。大三時看到一位厲害的學長分享Dcard實習，覺得裡面的人對技術都相當有熱忱，也在gopher conf聽了Dcard backend精彩的演講，於是這次完成了作業決定嘗試看看。
作業要求 Dcard 每天午夜都有大量使用者湧入抽卡，請設計一個 middleware：
 限制每小時來自同一個 IP 的請求數量不得超過 1000 在 response headers 中加入剩餘的請求數量 (X-RateLimit-Remaining) 以及 rate limit 歸零的時間 (X-RateLimit-Reset) 如果超過限制的話就回傳 429 (Too Many Requests) 可以使用各種資料庫達成  實做方式 限定只能用golang或nodejs，資料庫並沒有限制。我是以golang寫，資料庫的部份以單線程為主的redis，使得單個transaction不用考慮race condition，加上存取快速高併發的特性，以及方便的ttl對這次的作業十分友善，因此選擇redis作為這次作業的資料庫。至於來自不同client的get和set可能造成race condition，我在github repo中有詳細說明我如何實做lock。
一面 可以提早到hr會帶你參觀辦公室，由兩位backend面試後換hr面，先自我介紹約5-10分鐘，backend會針對以前的專案經驗追根究底的問，一定要對自己做過的專案非常熟悉，不然會和我一樣被問倒XD，加上以前在底層的計算機基礎知識不夠扎實，例如被問到為何mips要分成五個stage的pipeline來設計，當場腦袋空白只好說不知道，結果離開後馬上想到zzz。所以基礎也非常重要，面完就知道不會上了，期待蠻久的面試以失望落幕，果然自己還有許多基礎需要補足。和hr的面試就是一般的behavior問題，這個網路上有許多厲害的技巧分享，我就不多花篇幅了。
結果 感謝信
IBM (Associate developer) 官網投遞校園招募後一星期收到線上趣味測驗，趣味測驗結束就收到感謝信了。
結果 感謝信
Amazon Ring (SWE)   amazon ring
  官網投遞校園招募後一星期收到線上測驗。
Onsite Assignment 總共有三題，分別是easy, hard, medium。只能用四種語言: C, C++, Java, Python，職位的語言偏好也是前面的順序，第一次看到大科技公司對語言有偏好的，由於C-like的語言都不太熟，Java寫起來也不心安，雖然是最低順位的語言但也只能用Python了。</description>
    </item>
    
    <item>
      <title>About</title>
      <link>http://nathan-tw.github.io/about/</link>
      <pubDate>Thu, 22 Apr 2021 11:57:26 -0400</pubDate>
      
      <guid>http://nathan-tw.github.io/about/</guid>
      <description>I am Hsuan-Yo Lin </description>
    </item>
    
    <item>
      <title>[生活] 關於Star67</title>
      <link>http://nathan-tw.github.io/posts/star67/</link>
      <pubDate>Thu, 22 Apr 2021 07:56:39 -0400</pubDate>
      
      <guid>http://nathan-tw.github.io/posts/star67/</guid>
      <description>Star67 其實部落格的命名和星星完全沒有關係，大學時在新光路67號住了最久，也最喜歡在那生活的日子，所以部落格本想以此為名，不過如果取為New67或是Light67聽起來蠻蠢的，所以乾脆想成Star67aka星光路67號，而且在這的日子常常熬夜，五成是和朋友打傳說通霄，另外五成則是寫程式和書法到半夜停不下來所致，這些事的樂趣是日光還在時體會不到的，畢竟深夜才是適合苦惱的時候，而苦惱正是這些事精華之處。即使每天早上都不省人事，卻很享受這種報復性的作息，享受這種女友睡了，鄰居關燈了，剩下星光亮著的時光。
重蹈覆轍  愛是讓你不重蹈覆轍，讓你生而為人 &amp;ndash; 羅于婷 &amp;lt;喜歡的話可以試穿&amp;gt; ListList 其實大二大三時試著寫過medium，但一方面覺得自己的文章沒有質感，另一方面自己在技術上沒什麼可以分享或紀錄的，懷疑過現在的自己是否重蹈覆轍。直到最近聽到一首神曲走建國路回家但後座少ㄌ泥，我認為不管有沒有人看，寫的多爛，甚至什麼都沒學到，就去寫吧，寫的過程也許就是意義，一如那些星光陪伴的日子，寫下許多許多的字從來就不是為了讓誰滿意，而是我就想任性放肆的寫而已。
   </description>
    </item>
    
    <item>
      <title>[技術] Worker Pool併發處理模型</title>
      <link>http://nathan-tw.github.io/posts/worker-pool/</link>
      <pubDate>Mon, 19 Apr 2021 05:03:58 -0400</pubDate>
      
      <guid>http://nathan-tw.github.io/posts/worker-pool/</guid>
      <description>前陣子在準備Dcard實習的面試，看到別人的心得被問到如何以Golang實做一個Worker Pool，於是自己嘗試寫了一個。
什麼是Worker Pool Worker Pool是一個以multithread組成的任務處理模型，producer產生許多任務，並交由workers並行處理這些任務，最後將任務結果蒐集起來，這樣的作法可以有效的運用電腦資源，並快速處理重複性高且獨立的作業。
Worker Pool 設計 Type 定義 Worker Pool可以有一定數量的Workers(PoolSize)，並且可以指定一次處理的任務數量(tasksSize)，交由tasksChan送給worker，處理後再經由resultsChan存起來，待Results被呼叫時一一取出。而Task則是定義了id, error 和如何process的function。
type Task struct { Id int Err error f func() error } type WorkerPool struct { PoolSize int tasksSize int tasksChan chan Task resultsChan chan Task Results func() []Task } 功能實做 每一個任務處理完都會回傳error，如順利完成則回傳nil，至於任務如何執行則是依據新增任務時給定。
func (task *Task) Do() error { return task.f() Worker Pool是利用buffered channel做任務的通道，所以可以經由Start將worker一一執行起來後，讓worker利用range的特性不斷監聽是否有任務可以做。
func NewWorkerPool(tasks []Task, size int) *WorkerPool { tasksChan, resultsChan := make(chan Task, len(tasks)), make(chan Task, len(tasks)) for _, task := range tasks { tasksChan &amp;lt;- task } close(tasksChan) pool := &amp;amp;WorkerPool{ PoolSize: size, tasksSize: len(tasks), tasksChan: tasksChan, resultsChan: resultsChan, } pool.</description>
    </item>
    
    
    
  </channel>
</rss>
